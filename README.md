# üìä Predi√ß√£o de Pre√ßos de Im√≥veis com Machine Learning

## üìù Descri√ß√£o
Este projeto tem como objetivo prever o pre√ßo de im√≥veis a partir de diferentes vari√°veis (metragem, localiza√ß√£o, n√∫mero de quartos, etc.).  
Foram aplicadas t√©cnicas de **an√°lise explorat√≥ria, tratamento de dados, engenharia de atributos e compara√ß√£o de m√∫ltiplos modelos de Machine Learning**.  

---

## üìÇ Estrutura do Projeto
- **`MainProject.ipynb`** ‚Üí Notebook principal com todo o fluxo do projeto.  
- **`data/`** ‚Üí Pasta para armazenar o dataset bruto e processado (n√£o √© obrigat√≥rio subir no GitHub se os dados forem muito grandes).  
- **`models/`** ‚Üí Modelos salvos em `.pkl` para reutiliza√ß√£o.  
- **`README.md`** ‚Üí Descri√ß√£o do projeto.  

---

## ‚öôÔ∏è Tecnologias Utilizadas
- Python 3.11  
- Pandas, NumPy  
- Matplotlib, Seaborn, Plotly  
- Scikit-learn  
- Scipy  
- Statsmodels  
- Joblib  

---

## üìä Etapas do Projeto
1. **An√°lise Explorat√≥ria**  
   - Verifica√ß√£o de valores nulos, inconsistentes e outliers.  
   - Visualiza√ß√µes de distribui√ß√µes e correla√ß√µes.  

2. **Pr√©-processamento**  
   - Tratamento e remo√ß√£o de outliers.   
   - Normaliza√ß√£o/Padroniza√ß√£o de vari√°veis num√©ricas (`StandardScaler`).  

3. **Modelagem**  
   - Modelos testados:  
     - Decision Tree
     - Knn 
     - Random Forest Regressor  
     - Support Vector Regressor (SVR)  
     - Rede Neural (MLP)  
     - Linear Regression 
     - GradientBoostingRegressor
   - Ajuste de hiperpar√¢metros com `GridSearchCV` e `RandomizedSearchCV`.  

4. **Compara√ß√£o de Modelos**  
   - M√©tricas utilizadas:  
     Para comparar os modelos de forma justa, utilizei o m√©todo **MultiComparison** da biblioteca `statsmodels`.  
      Esse m√©todo permite realizar testes estat√≠sticos (ex: Tukey HSD) para verificar se as diferen√ßas de desempenho entre os modelos s√£o **estatisticamente significativas** e n√£o apenas resultado de varia√ß√µes aleat√≥rias.
   - Testes feitos com **dados originais** e **dados tratados sem outliers**.  

5. **Resultados**  
   - Tabela comparativa destacando o melhor modelo.  
   - Conclus√£o sobre o impacto do tratamento de outliers no desempenho.  

6. **Deploy Local**  
   - Modelo vencedor salvo em `.pkl` com `joblib`.  
   - Pode ser carregado em outros projetos ou APIs para previs√£o.  

---

## üöÄ Como Rodar
1. Clone este reposit√≥rio:  
   ```bash
   git clone https://github.com/PedroHenriqueBRO/HousePrediction-ML-Models.git #para HTTPS
   git clone git@github.com:PedroHenriqueBRO/HousePrediction-ML-Models.git #para SSH
   cd HousePrediction-ML-Models
   ```
2. Crie um ambiente virtual e instale as depend√™ncias:  
   ```bash
   pip install -r requirements.txt
   ```
3. Abra o notebook:  
   ```bash
   jupyter notebook MainProject.ipynb
   ```
4. Para carregar o modelo final:  
   ```python
   import joblib
   modelo = joblib.load("models/MelhorModelo(GBR).pkl")
   previsao = modelo.predict(novos_dados)
   ```

---

## üìà Resultados Finais
- Melhor modelo: **[GBR]**  
- Quando treinado diretamente com a base de dados com ru√≠do e utilizando o score sobre esses mesmos dados ele apresenta score de 97%.
J√° quando colocado para fazer o mesmo processo mas com a base sem ru√≠do ele apresenta score de 68%.
---

## üìå Conclus√£o
- O tratamento de outliers impactou diretamente na performance.  
- Comparando diferentes algoritmos, **[GBR]** apresentou o melhor desempenho.  
- O pipeline criado √© reaproveit√°vel para novos datasets.  
